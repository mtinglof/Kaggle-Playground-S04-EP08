{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mtinglof/i-don-t-feel-so-good?scriptVersionId=193650380\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Resources \n## Links \n* https://www.kaggle.com/code/satyaprakashshukl/mushroom-classification-analysis/notebook\n* https://www.kaggle.com/code/ambrosm/pss4e8-eda-which-makes-sense#First-observations \n* https://www.kaggle.com/code/annastasy/ps4e8-data-cleaning-and-eda-of-mushrooms\n\n## Code Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-22T21:52:40.098264Z","iopub.execute_input":"2024-08-22T21:52:40.099231Z","iopub.status.idle":"2024-08-22T21:52:55.738364Z","shell.execute_reply.started":"2024-08-22T21:52:40.099194Z","shell.execute_reply":"2024-08-22T21:52:55.737091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Problem Definition\n## 1.1 Scenario\n\nWelcome back! Today, our client has given us the task of binary classification of mushrooms. The client lives far out in a magical forest and needs an application to help her identify which mushrooms she can eat and which she cannot. Luckily for us, she brought with her an ancient tome of mushroom classification. The book is pretty old, though, and some of the text is messed up- so we will have to work around that. She is hoping that we can come up with a model, so she does not have to flip through every page of this massive book. Oh, and she's hoping that your model will not get her sick either! \n\n## 1.2 Scoring Metric\nFor our client, we will be using the Matthews correlation coefficient (MCC). What does this mean? The MCC is a scoring equation that is calculated using true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). For you nerds, here is the full equation. \n\n$$\n\\text{MCC} = \\frac{(TP \\times TN) - (FP \\times FN)}{\\sqrt{(TP + FP) \\times (TP + FN) \\times (TN + FP) \\times (TN + FN)}}\n$$\n\nThe MCC is great for binary classification, especially where datasets are imbalanced in favor of one type of classification. The other thing to know is that this equation will give us a score from -1 to 1, where -1 is total misclassification, 0 is no predictive power (randomly guessing), and 1 is a perfect classification. \n\n# 2. Data Collection and Analysis\n## 2.1 Import Data and Look at Raw Reads\nAlright, let's look at this data that our client has collect from her massive tome.  ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/playground-series-s4e8/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s4e8/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:52:55.740686Z","iopub.execute_input":"2024-08-22T21:52:55.741554Z","iopub.status.idle":"2024-08-22T21:53:12.957367Z","shell.execute_reply.started":"2024-08-22T21:52:55.741505Z","shell.execute_reply":"2024-08-22T21:53:12.956367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:12.958645Z","iopub.execute_input":"2024-08-22T21:53:12.958973Z","iopub.status.idle":"2024-08-22T21:53:12.993725Z","shell.execute_reply.started":"2024-08-22T21:53:12.958946Z","shell.execute_reply":"2024-08-22T21:53:12.9926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:12.996134Z","iopub.execute_input":"2024-08-22T21:53:12.996484Z","iopub.status.idle":"2024-08-22T21:53:13.024509Z","shell.execute_reply.started":"2024-08-22T21:53:12.996454Z","shell.execute_reply":"2024-08-22T21:53:13.02327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Visualizations\nThe biggest problem we are going to have with this dataset is the number of artifacts that can be found in each column. ","metadata":{}},{"cell_type":"code","source":"unique_counts = {}\n\nfor column in train_df.columns:\n    unique_counts[column] = train_df[column].nunique()\n\nunique_counts_series = pd.Series(unique_counts)\n\nprint(unique_counts_series)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:13.02577Z","iopub.execute_input":"2024-08-22T21:53:13.026082Z","iopub.status.idle":"2024-08-22T21:53:14.579177Z","shell.execute_reply.started":"2024-08-22T21:53:13.026056Z","shell.execute_reply":"2024-08-22T21:53:14.578022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the table above, we see that there are quite a few unique values per column. In addition, it does not seem that the data dictionary found [here](https://www.kaggle.com/competitions/playground-series-s4e8/data) or [here](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset) correlates exactly with our dataset. While it seems very close, both data dictionaries do not seem to describe all variables in our dataset. Lets see what percentage each value makes in each column with the code below. ","metadata":{}},{"cell_type":"code","source":"def calculate_category_percentages(df):\n    for column in df.columns:\n        if df[column].dtype == 'object':\n            print(f\"Column: {column}\")\n            percentage = df[column].value_counts(normalize=True) * 100\n            print(f\"{percentage.to_string()}\\n\")\n\ncalculate_category_percentages(train_df)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-22T21:53:14.580803Z","iopub.execute_input":"2024-08-22T21:53:14.581189Z","iopub.status.idle":"2024-08-22T21:53:17.082534Z","shell.execute_reply.started":"2024-08-22T21:53:14.581148Z","shell.execute_reply":"2024-08-22T21:53:17.081222Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we are trying to reduce these values per column, a good cutoff looks like any row value that is < .1% of the total count values in a column. We will handle that in our data cleaning section. \n\nLets take a look at the null values now. ","metadata":{}},{"cell_type":"code","source":"null_counts = train_df.isnull().sum()\nnull_counts = null_counts.sort_values(ascending=False)\n\nprint(null_counts)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=null_counts.index, y=null_counts.values, palette='viridis')\n\nplt.title('Number of Null Values in Each Column')\nplt.xlabel('Column Names')\nplt.ylabel('Number of Null Values')\nplt.xticks(rotation=90)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:17.084143Z","iopub.execute_input":"2024-08-22T21:53:17.084527Z","iopub.status.idle":"2024-08-22T21:53:19.862357Z","shell.execute_reply.started":"2024-08-22T21:53:17.0845Z","shell.execute_reply":"2024-08-22T21:53:19.861222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE** The numerical column **cap-diameter** has 4 null values. If you miss this, you're going to have some head scratching errors with training later. ","metadata":{}},{"cell_type":"code","source":"duplicate_count = train_df.duplicated().sum()\n\nprint(f\"Number of duplicate rows: {duplicate_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:19.863603Z","iopub.execute_input":"2024-08-22T21:53:19.863933Z","iopub.status.idle":"2024-08-22T21:53:24.114661Z","shell.execute_reply.started":"2024-08-22T21:53:19.863904Z","shell.execute_reply":"2024-08-22T21:53:24.11361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No duplicate rows, good to know. \n\nFinally, lets get some plots of our numerical data.","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:48:35.436017Z","iopub.status.idle":"2024-08-22T18:48:35.436411Z","shell.execute_reply.started":"2024-08-22T18:48:35.436211Z","shell.execute_reply":"2024-08-22T18:48:35.436227Z"}}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\nfor i, col in enumerate(train_df.select_dtypes(include=['float64']).columns):\n    axes[i].hist(train_df[col], bins=30, color='skyblue', edgecolor='black')\n    axes[i].set_title(f'Histogram of {col}')\n    axes[i].set_xlabel(col)\n    axes[i].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:24.116153Z","iopub.execute_input":"2024-08-22T21:53:24.116608Z","iopub.status.idle":"2024-08-22T21:53:25.09611Z","shell.execute_reply.started":"2024-08-22T21:53:24.116569Z","shell.execute_reply":"2024-08-22T21:53:25.09493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 First Thoughts\n* We have a **ton** of training data. Good news for us, we will be able to split this into a train, dev, test set. \n* There are a lot of data artifacts in the set. In the next section, we will define .1% as the cutoff for artifacts that will get reassigned to another value. \n* Null values will also have to be handled. \n* No duplicates, that's a good sign. \n\n# 3. Data Cleaning\n## 3.1 Replacing Null and Artifacts\nNow that we have a good sense of what data we are working with, let's get it ready for a model. First, let's handle those data artifacts by writing a function to rewrite those smaller values and any null values we might have. Intuitively, we know already that we are probably going to be using a Deep Neural Network (DNN) for this problem. ","metadata":{}},{"cell_type":"code","source":"for col in train_df.select_dtypes(include=['float64']).columns:\n    train_df[col] = train_df[col].fillna(0)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:25.099637Z","iopub.execute_input":"2024-08-22T21:53:25.100005Z","iopub.status.idle":"2024-08-22T21:53:25.16585Z","shell.execute_reply.started":"2024-08-22T21:53:25.099976Z","shell.execute_reply":"2024-08-22T21:53:25.164776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rewrite_values(df, threshold=0.1):\n    for column in df.columns:\n        if df[column].dtype == 'object':\n            total_count = df[column].notna().sum()\n            value_counts = df[column].value_counts()\n            replace_dict = {value: 'not' if count / total_count < (threshold / 100) else value for value, count in value_counts.items()}\n            df[column] = df[column].map(replace_dict).fillna('null')\n\nrewrite_values(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:25.167395Z","iopub.execute_input":"2024-08-22T21:53:25.167765Z","iopub.status.idle":"2024-08-22T21:53:37.049329Z","shell.execute_reply.started":"2024-08-22T21:53:25.167736Z","shell.execute_reply":"2024-08-22T21:53:37.048321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_counts = {}\n\nfor column in train_df.columns:\n    unique_counts[column] = train_df[column].nunique()\n\nunique_counts_series = pd.Series(unique_counts)\n\nprint(unique_counts_series)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:37.050456Z","iopub.execute_input":"2024-08-22T21:53:37.05089Z","iopub.status.idle":"2024-08-22T21:53:40.656816Z","shell.execute_reply.started":"2024-08-22T21:53:37.050852Z","shell.execute_reply":"2024-08-22T21:53:40.655711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Prepare Data for Model\nAlright, we handled our null values and data artifacts. Below, we are going to one hot encode our categorical values. I won't explain one hot encoding, but you can find a summary [here](https://www.geeksforgeeks.org/ml-one-hot-encoding/). We are also going to normalize our continuous variables between 0 and 1 for the NN. High level: we normalize our continuous variables to help with training our NN.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\n\ndf_encoded = pd.get_dummies(train_df, columns=train_df.select_dtypes(include=['object']).columns, dtype=int)\ncontinuous_cols = df_encoded.select_dtypes(include=['float64']).columns\ndf_encoded[continuous_cols] = scaler.fit_transform(df_encoded[continuous_cols])\n\ndf_encoded = df_encoded.drop(['id'], axis=1)\n\npd.set_option('display.max_columns', None)\ndf_encoded.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:40.658628Z","iopub.execute_input":"2024-08-22T21:53:40.659041Z","iopub.status.idle":"2024-08-22T21:53:55.61127Z","shell.execute_reply.started":"2024-08-22T21:53:40.659005Z","shell.execute_reply":"2024-08-22T21:53:55.610137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Creating our Train and Dev Sets\nSince our data set is so large, we will be able to train a very accurate deep neural network. Additionally, we will be able to have three data sets- train, dev, and test sets. We will want our largest dataset to be the training set (duh) while we can keep our other two datasets relatively small <50k rows. Below, we do a 99.98%/.01%/.01% data split (very small!). ","metadata":{}},{"cell_type":"code","source":"df_encoded_x = df_encoded.drop(columns=['class_e', 'class_p'])\ndf_encoded_y = df_encoded['class_e']","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:55.612624Z","iopub.execute_input":"2024-08-22T21:53:55.613052Z","iopub.status.idle":"2024-08-22T21:53:56.846855Z","shell.execute_reply.started":"2024-08-22T21:53:55.613014Z","shell.execute_reply":"2024-08-22T21:53:56.845532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_x, temp_data_x, train_data_y, temp_data_y = train_test_split(df_encoded_x, df_encoded_y, test_size=0.02, random_state=16)\ndev_data_x, test_data_x, dev_data_y, test_data_y = train_test_split(temp_data_x, temp_data_y, test_size=.5, random_state=16)\n\nprint(f\"Train set size: {len(train_data_x)} rows\")\nprint(f\"Dev set size: {len(dev_data_x)} rows\")\nprint(f\"Test set size: {len(test_data_x)} rows\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:53:56.848417Z","iopub.execute_input":"2024-08-22T21:53:56.84887Z","iopub.status.idle":"2024-08-22T21:54:04.909593Z","shell.execute_reply.started":"2024-08-22T21:53:56.848827Z","shell.execute_reply":"2024-08-22T21:54:04.908144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 Initial Model Testing\n## 4.1 Define a Custom MCC Metric Function\nRemember that scoring metric we mentioned earlier? Tensorflow has depreciated that [metric](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/MatthewsCorrelationCoefficient), so we will have to define our own.","metadata":{}},{"cell_type":"code","source":"def mcc(y_true, y_pred):\n    y_pred_pos = tf.round(tf.clip_by_value(y_pred, 0, 1))\n    y_pred_neg = 1 - y_pred_pos\n\n    y_true_pos = tf.round(tf.clip_by_value(y_true, 0, 1))\n    y_true_neg = 1 - y_true_pos\n\n    y_pred_pos = tf.cast(y_pred_pos, tf.float32)\n    y_pred_neg = tf.cast(y_pred_neg, tf.float32)\n    y_true_pos = tf.cast(y_true_pos, tf.float32)\n    y_true_neg = tf.cast(y_true_neg, tf.float32)\n\n    tp = tf.reduce_sum(y_true_pos * y_pred_pos)\n    tn = tf.reduce_sum(y_true_neg * y_pred_neg)\n    fp = tf.reduce_sum(y_true_neg * y_pred_pos)\n    fn = tf.reduce_sum(y_true_pos * y_pred_neg)\n\n    numerator = (tp * tn) - (fp * fn)\n    denominator = tf.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n\n    mcc = tf.where(tf.math.equal(denominator, 0), 0.0, numerator / denominator)\n    return mcc","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:54:04.910962Z","iopub.execute_input":"2024-08-22T21:54:04.911396Z","iopub.status.idle":"2024-08-22T21:54:04.92004Z","shell.execute_reply.started":"2024-08-22T21:54:04.911359Z","shell.execute_reply":"2024-08-22T21:54:04.918847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Define a DNN\nBelow we will define a very simple DNN, with two hidden layers, with the specific parameters listed in the code. We are going to use binary cross entropy as our loss function, but in future iterations, we will consider using our custom MCC function as the loss function. \n\nBeware, using a custom loss function can introduce unforeseen complexity and issues in an optimization problem. Training our model using binary cross entropy and our custom loss function will give us a good idea of comparison between the two.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(train_data_x.shape[1],)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=[mcc])","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:54:04.921608Z","iopub.execute_input":"2024-08-22T21:54:04.922007Z","iopub.status.idle":"2024-08-22T21:54:05.057445Z","shell.execute_reply.started":"2024-08-22T21:54:04.921973Z","shell.execute_reply":"2024-08-22T21:54:05.056286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DNN = model.fit(train_data_x, train_data_y, epochs=5, batch_size=512, validation_data = (dev_data_x, dev_data_y))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:54:05.058917Z","iopub.execute_input":"2024-08-22T21:54:05.059375Z","iopub.status.idle":"2024-08-22T21:55:52.820782Z","shell.execute_reply.started":"2024-08-22T21:54:05.059333Z","shell.execute_reply":"2024-08-22T21:55:52.819381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Already we see our model performing very well in just 5 epcohs. \n# 5 Initial Model Validation\n## 5.1 Loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(DNN.history['loss'], label='Training Loss')\nplt.plot(DNN.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:52.822741Z","iopub.execute_input":"2024-08-22T21:55:52.823125Z","iopub.status.idle":"2024-08-22T21:55:53.151129Z","shell.execute_reply.started":"2024-08-22T21:55:52.823092Z","shell.execute_reply":"2024-08-22T21:55:53.149967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 MCC Metric","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(DNN.history['mcc'], label='Training MCC')\nplt.plot(DNN.history['val_mcc'], label='Validation MCC')\nplt.title('Training and Validation MCC')\nplt.xlabel('Epochs')\nplt.ylabel('MCC')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:53.152647Z","iopub.execute_input":"2024-08-22T21:55:53.153087Z","iopub.status.idle":"2024-08-22T21:55:53.413334Z","shell.execute_reply.started":"2024-08-22T21:55:53.153049Z","shell.execute_reply":"2024-08-22T21:55:53.411983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Difference between training and validation MCC metric:\\n{abs(DNN.history['mcc'][-1] - DNN.history['val_mcc'][-1])}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:53.414681Z","iopub.execute_input":"2024-08-22T21:55:53.415023Z","iopub.status.idle":"2024-08-22T21:55:53.421332Z","shell.execute_reply.started":"2024-08-22T21:55:53.414992Z","shell.execute_reply":"2024-08-22T21:55:53.420174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our test data MCC metric is very low, which means our model fits very well to this set (low bias). The final difference between our training MCC metric and our validation MCC metric is also very small, which means our model is able to generalize efficently (low variance)!  \n## 5.3 Test Data Set - Final Model Evaluation","metadata":{}},{"cell_type":"code","source":"test_loss, test_metrics = model.evaluate(test_data_x, test_data_y)\n\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Metrics: {test_metrics}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:53.422587Z","iopub.execute_input":"2024-08-22T21:55:53.422918Z","iopub.status.idle":"2024-08-22T21:55:54.700063Z","shell.execute_reply.started":"2024-08-22T21:55:53.422886Z","shell.execute_reply":"2024-08-22T21:55:54.698762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Difference between training and test MCC metric:\\n{abs(DNN.history['mcc'][-1] - test_metrics)}\")\nprint(f\"\\nDifference between validation and test MCC metric:\\n{abs(DNN.history['val_mcc'][-1] - test_metrics)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:54.701496Z","iopub.execute_input":"2024-08-22T21:55:54.701904Z","iopub.status.idle":"2024-08-22T21:55:54.709171Z","shell.execute_reply.started":"2024-08-22T21:55:54.701871Z","shell.execute_reply":"2024-08-22T21:55:54.707779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What we are looking for here is our training, validation, and test metric. \n\nIf the difference going from training -> test data is high, that means we might have overfitted our model to the training and validation data (high variance). \n\nIf the difference going from validation -> test data is high, that means we might have just overfitted on the validation data. This could also mean that our validation data and our test data do not come from the same distribution, which is also a problem we should check. \n\nSince both differences in MCC metrics are low, this means our model is generalizing well to the test data set, and our test data set is probably from the same distribution of data as our validation data set. \n# 6 Model Deployment\n## 6.1 Data Aggregation Pipeline\nIt is time to deploy our model and see how it works in a production environment! First we will need to define a data pipeline to apply all our data aggregation methods in a streamlined fashion. We will reuse the code we wrote above for this process.","metadata":{}},{"cell_type":"code","source":"def remove_num_na(df):\n    for col in df.select_dtypes(include=['float64']).columns:\n        df[col] = df[col].fillna(0)\n    return df\n\ndef rewrite_values(df, threshold=0.1):\n    for column in df.columns:\n        if df[column].dtype == 'object':\n            total_count = df[column].notna().sum()\n            value_counts = df[column].value_counts()\n            replace_dict = {\n                value: 'not' if count / total_count < (threshold / 100) else value for value, count in value_counts.items()}\n            df[column] = df[column].map(replace_dict).fillna('null')\n    return df\n\ndef normalize(df): \n    scaler = MinMaxScaler()\n    continuous_cols = df.select_dtypes(include=['float64']).columns\n    df[continuous_cols] = scaler.fit_transform(df[continuous_cols])\n    return df\n\ndef encode(df): \n    df = pd.get_dummies(df, columns=df.select_dtypes(include=['object']).columns, dtype=int)\n    return df\n    \ndef data_pipeline(df):\n    df = remove_num_na(df)\n    df = rewrite_values(df)\n    df = normalize(df)\n    df = encode(df)\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T21:55:54.710829Z","iopub.execute_input":"2024-08-22T21:55:54.711356Z","iopub.status.idle":"2024-08-22T21:55:54.723543Z","shell.execute_reply.started":"2024-08-22T21:55:54.711314Z","shell.execute_reply":"2024-08-22T21:55:54.722387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = test_df['id']\ntest_features = test_df.drop(columns=['id'])\n\ndf_prod = data_pipeline(test_features)\npredictions = model.predict(df_prod)\n\npredicted_classes = (predictions > 0.5).astype(int)\nsubmission_df = pd.DataFrame({\n    'id': test_ids,\n    'class' : pd.Series(predicted_classes.flatten()).map({1: \"e\", 0: \"p\"})\n})\n\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T22:17:47.474236Z","iopub.execute_input":"2024-08-22T22:17:47.476352Z","iopub.status.idle":"2024-08-22T22:19:53.714931Z","shell.execute_reply.started":"2024-08-22T22:17:47.476268Z","shell.execute_reply":"2024-08-22T22:19:53.713748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T22:22:24.758863Z","iopub.execute_input":"2024-08-22T22:22:24.759285Z","iopub.status.idle":"2024-08-22T22:22:26.410252Z","shell.execute_reply.started":"2024-08-22T22:22:24.759251Z","shell.execute_reply":"2024-08-22T22:22:26.40915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}